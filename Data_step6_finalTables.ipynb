{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install python-dotenv\n",
    "# %pip install seaborn\n",
    "# %pip install tensorflow_data_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pygeos as pg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following lines adjust the granularity of reporting.\n",
    "#pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "os.chdir('/tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGPDfromPD(df: pd.DataFrame, geomCol: str, crs: str = \"EPSG:3978\") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Convert a pandas dataframe to a geopandas dataframe\n",
    "    :param df: pandas dataframe\n",
    "    :param geomCol: name of the geometry column\n",
    "    :param crs: coordinate reference system\n",
    "    :return: geopandas dataframe\n",
    "    \"\"\"\n",
    "    if 'geom' in df.columns:\n",
    "        df.rename(columns={'geom': 'geometry'}, inplace=True)\n",
    "\n",
    "    df[geomCol] = df[geomCol].apply(wkt.loads)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geomCol, crs=crs)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = \"Data/GEOProvincialBoundaries.csv\"\n",
    "dfProvinces = pd.read_csv(provinces)\n",
    "dfProvinces['geom'] = dfProvinces['geom'].apply(wkt.loads)\n",
    "gdfProvinces = gpd.GeoDataFrame(dfProvinces, geometry='geom', crs=\"EPSG:3347\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fire data\n",
    "fireTable = \"Data/GEOlgFireFifty.csv\"\n",
    "dfFire = pd.read_csv(fireTable)\n",
    "dfFire['geom'] = dfFire['geom'].apply(wkt.loads)\n",
    "gdfFire = gpd.GeoDataFrame(dfFire, geometry='geom', crs=\"EPSG:3347\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot both to check\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "gdfProvinces.plot(ax=ax, color='white', edgecolor='black')\n",
    "gdfFire.plot(ax=ax, color='red', markersize=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = \"Data/GEOlgFireFiftyCentroids.csv\"\n",
    "dfCentroids = pd.read_csv(centroids)\n",
    "dfCentroids['geom'] = dfCentroids['geom'].apply(wkt.loads)\n",
    "gdfCentroids = gpd.GeoDataFrame(dfCentroids, geometry='geom', crs=\"EPSG:3347\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot both to check\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "gdfProvinces.plot(ax=ax, color='white', edgecolor='black')\n",
    "gdfCentroids.plot(ax=ax, color='red', markersize=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfFire['size_ha_bin'] = pd.qcut(dfFire['SIZE_HA'], 4, labels=False)\n",
    "gdfFire.drop(columns=['DECADE', 'CALC_HA', 'CFS_REF_ID', 'CAUSE', 'OUT_DATE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join fire with centroids\n",
    "gdfMerged = gdfFire.merge(dfCentroids, on='EntryID', how='left')\n",
    "gdfMerged.set_geometry('geom_y')\n",
    "gdfMerged.drop(columns=['geom_x'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use fire name where fire id is null\n",
    "gdfMerged['FIRE_ID'].fillna(gdfMerged['FIRENAME'], inplace=True)\n",
    "# use fire id where fire name is null\n",
    "gdfMerged['FIRENAME'].fillna(gdfMerged['FIRE_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyWeather = \"Data/WeatherDataHourlyAggDaily.csv\"\n",
    "dfWeather = pd.read_csv(dailyWeather)\n",
    "dfWeather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeather.astype({'ClimateID': 'str', 'ProvinceCode': 'str', \n",
    "                'Year': 'int', 'Month': 'int', 'Day': 'int',\n",
    "                'MeanTemp': 'float', 'MinTemp': 'float', 'MaxTemp': 'float',\n",
    "                'MeanDewPoint': 'float', 'MinDewPoint': 'float', 'MaxDewPoint': 'float',\n",
    "                'MeanHumidity': 'float', 'MinHumidity': 'float', 'MaxHumidity': 'float',\n",
    "                'MeanPressure': 'float', 'MinPressure': 'float', 'MaxPressure': 'float',\n",
    "                'MeanWindSpeed': 'float', 'MinWindSpeed': 'float', 'MaxWindSpeed': 'float',\n",
    "                'MeanWindChill': 'float', 'MinWindChill': 'float', 'MaxWindChill': 'float',\n",
    "                'TotalPrecip': 'float', 'MeanWindDirection': 'float'}, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = \"Data/climate_station_list.csv\"\n",
    "dfAllStations = pd.read_csv(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStationIDGeom = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load firewaterelev\n",
    "fireWaterElev = \"Data/FireWaterElev.csv\"\n",
    "dfFireWaterElev = pd.read_csv(fireWaterElev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfFireWaterElev.count())\n",
    "print(dfFireWaterElev.describe())\n",
    "print(dfFireWaterElev.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fire centroids \n",
    "fireCentroids = \"Data/GEOlgFireFiftyCentroids.csv\"\n",
    "dfTemp = pd.read_csv(fireCentroids)\n",
    "\n",
    "dfCentroids = getGPDfromPD(dfTemp, 'geometry')\n",
    "print(dfCentroids.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTemp = dfCentroids.merge(dfFireWaterElev, on='EntryID', how='inner')\n",
    "# dfTemp = dfFireWaterElevGPD.merge(dfCentroids, on='EntryID', how='left')\n",
    "\n",
    "print(dfTemp.columns)\n",
    "dfFireWECent = dfTemp\n",
    "\n",
    "print(dfFireWECent.count())\n",
    "print(dfFireWECent.columns)\n",
    "print(dfFireWECent.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = \"Data/GEOTenYrStationsHourly.csv\"\n",
    "dfTemp = pd.read_csv(stations)\n",
    "\n",
    "dfStations = getGPDfromPD(dfTemp, 'geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfFireWECent.drop(columns=['ClimateID'], inplace=True)\n",
    "\n",
    "# keep only Province == SASKATCHEWAN\n",
    "dfStations = dfStations[dfStations['Province'] == 'SASKATCHEWAN']\n",
    "dfStations.drop(columns=['dataAvailable'], inplace=True)\n",
    "print(dfStations.columns)\n",
    "print(dfStations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpd sjoin to find nearest station to each fire\n",
    "dfNearest = gpd.sjoin_nearest(dfFireWECent, dfStations, how='left', max_distance=117590)\n",
    "print(dfNearest.count())\n",
    "print(dfNearest.columns)\n",
    "print(dfNearest.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with nan values\n",
    "dfNearest.dropna(inplace=True)\n",
    "print(dfNearest.count())\n",
    "print(dfNearest.columns)\n",
    "print(dfNearest.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNearest.drop(columns=['ClimateID_left'], inplace=True)\n",
    "dfNearest.rename(columns={'ClimateID_right': 'ClimateID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherDaily = \"Data/WeatherDataHourlyAggDaily.csv\"\n",
    "dfWeatherDaily = pd.read_csv(weatherDaily)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfWeatherDaily.count())\n",
    "print(dfWeatherDaily.describe())\n",
    "print(dfWeatherDaily.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dfWeatherDaily columns to use all caps for year month day\n",
    "dfWeatherDaily.rename(columns={'climateid': 'ClimateID', 'Year': 'YEAR', 'Month': 'MONTH', 'Day': 'DAYw', 'utc': 'utcWeather'}, inplace=True)\n",
    "print(dfWeatherDaily.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfNearest.dtypes)\n",
    "print(dfWeatherDaily.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfAll = dfFireWECent.copy(deep=True)\n",
    "\n",
    "# dfAll.rename(columns={'utc': 'utcFire'}, inplace=True)\n",
    "# # left join dfAll and dfWeatherDaily on ClimateID and YEAR MONTH\n",
    "# dfAll = dfAll.merge(dfWeatherDaily, on=['ClimateID', 'YEAR', 'MONTH', 'DAY'], how='left')\n",
    "\n",
    "\n",
    "# print(dfAll.columns)\n",
    "# print(dfFireWECent.count())\n",
    "# print(dfAll.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNearest.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNearest['ClimateID'] = dfNearest['ClimateID'].astype(str)\n",
    "dfWeatherDaily['ClimateID'] = dfWeatherDaily['ClimateID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join dfAll plus weather\n",
    "\n",
    "dfAll = dfNearest.copy(deep=True)\n",
    "\n",
    "dfAll.rename(columns={'utc': 'utcFire'}, inplace=True)\n",
    "# left join dfAll and dfWeatherDaily on ClimateID and YEAR and MONTH\n",
    "dfAll = dfAll.merge(dfWeatherDaily, on=['ClimateID', 'MONTH', 'YEAR'], how='left')\n",
    "print(dfAll.head())\n",
    "# keep only rows where utcWeather = utcFire - ONEDAY\n",
    "dfAll = dfAll[(dfAll['DAYw'] == dfAll['DAY'] - 1)]\n",
    "\n",
    "print(dfAll.columns)\n",
    "print(dfNearest.count())\n",
    "print(dfAll.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print rows with NaN values\n",
    "print(dfAll[dfAll.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first read in the csv file into pd\n",
    "dfTemp = pd.read_csv('Data/GEOProvincialBoundaries.csv')\n",
    "\n",
    "dfProvinces = getGPDfromPD(dfTemp, 'geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only dfNearest where geomtry is containe din dfProvinces Saskatchewan\n",
    "dfAll['keep'] = False\n",
    "for index, row in dfAll.iterrows():\n",
    "    if dfProvinces[dfProvinces['provID'] == 'SK'].contains(row['geometry']).any():\n",
    "        dfAll.at[index, 'keep'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfAll.head())\n",
    "print(dfAll.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = dfAll[dfAll['keep'] == True]\n",
    "print(dfAll.head())\n",
    "print(dfAll.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll.drop(columns=['MeanTemp', 'MinTemp', 'MeanDewPoint', 'MinDewPoint', 'MaxDewPoint',\n",
    "                    'MinHumidity', 'MaxHumidity', 'MeanPressure', 'MinPressure',\n",
    "                    'MaxPressure', 'MinWindSpeed', 'MeanWindChill', 'MinWindChill', 'MaxWindChill',\n",
    "                    'MeanWindDirection' ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRain = dfAll.copy(deep = True)\n",
    "dfRain['Rain'] = (dfRain['TotalPrecip'] > 0).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRain['Longitude'] = dfRain['geometry'].x\n",
    "dfRain['Latitude'] = dfRain['geometry'].y\n",
    "print(dfRain.head())\n",
    "print(dfRain.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create longitude binned column\n",
    "dfRain['LongitudeBin'], longBins = pd.cut(dfRain['Longitude'], 570, labels=False, retbins=True)\n",
    "dfRain['LatitudeBin'], latBins = pd.cut(dfRain['Latitude'], 570, labels=False, retbins=True)\n",
    "print(dfRain.head())\n",
    "print(dfRain.count())\n",
    "print(longBins)\n",
    "print(latBins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot LongitudeBin vs LatitudeBin scatter plot\n",
    "dfRain.plot.scatter(x='LongitudeBin', y='LatitudeBin', c='blue', colormap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dfRain to csv\n",
    "dfRain.to_csv('Data/FinalFeature.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
