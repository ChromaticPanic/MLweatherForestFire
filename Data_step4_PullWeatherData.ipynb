{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Objective of this notebook is to go through a list of weather stations and collect the weather data for each station. The data is collected from the Canada open data portal. Data for each station is combined into a single table then stored in a database for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 16:48:49.032148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 16:48:49.152743: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pygeos as pg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sqlalchemy as sq\n",
    "import ipyparallel as ipp\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from ClimateDataRequester import ClimateDataRequester as cdr\n",
    "\n",
    "# The following lines adjust the granularity of reporting.\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.chdir('/tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection_url = \"postgresql://grpthreeuser:grpthreeuser@postgres:5432/grpthreedb\"\n",
    "engine = sq.create_engine(db_connection_url)\n",
    "db_con = engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableName = \"public.\\\"lgFireStationsTen\\\"\"\n",
    "query = \"SELECT * FROM \" + tableName + \";\"\n",
    "dfStations = gpd.GeoDataFrame.from_postgis(query, db_con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_data(df: pd.DataFrame) -> None:\n",
    "    df.to_sql(\"WeatherData\", db_con, if_exists=\"append\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProcessA(df: pd.DataFrame, stationID: str) -> None:\n",
    "    try:\n",
    "        df.drop(columns=['Data Quality', 'Max Temp Flag', 'Mean Temp Flag', 'Min Temp Flag', 'Heat Deg Days Flag', 'Cool Deg Days Flag', 'Spd of Max Gust (km/h)',\n",
    "                         'Total Rain Flag', 'Total Snow Flag', 'Total Precip Flag', 'Snow on Grnd Flag', 'Dir of Max Gust Flag', 'Spd of Max Gust Flag',\n",
    "                         'Heat Deg Days (°C)', 'Cool Deg Days (°C)', 'Longitude (x)', 'Latitude (y)', 'Station Name', 'Dir of Max Gust (10s deg)'], inplace=True)\n",
    "    except:\n",
    "        df.to_csv(\"Failed/\" + str(df.iloc[0, 0]) +\n",
    "                  \"_unexpected_column_names.csv\", index=False)\n",
    "\n",
    "    # Climate ID\tDate/Time\tYear\tMonth\tDay\tMax Temp (Â°C)\tMin Temp (Â°C)\tMean Temp (Â°C)\tTotal Rain (mm)\tTotal Snow (cm)\tTotal Precip (mm)\tSnow on Grnd (cm)\tDir of Max Gust (10s deg)\tSpd of Max Gust (km/h)\n",
    "    # ClimateID Date Year Month Day MaxTemp MinTemp MeanTemp TotalRain TotalSnow TotalPrecip SnowOnGrnd DirOfMaxGust SpdOfMaxGust\n",
    "    df.rename(columns={df.columns[0]: \"ClimateID\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[1]: \"Date\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[2]: \"Year\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[3]: \"Month\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[4]: \"Day\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[5]: \"MaxTemp\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[6]: \"MinTemp\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[7]: \"MeanTemp\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[8]: \"TotalRain\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[9]: \"TotalSnow\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[10]: \"TotalPrecip\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[11]: \"SnowOnGrnd\"}, inplace=True)\n",
    "\n",
    "    df.dropna(subset=['MeanTemp'], inplace=True)\n",
    "    df.loc[df['SnowOnGrnd'].isnull(), 'SnowOnGrnd'] = 0\n",
    "    df.loc[df['TotalRain'].isnull(), 'TotalRain'] = 0\n",
    "    df.loc[df['TotalSnow'].isnull(), 'TotalSnow'] = 0\n",
    "    df.loc[df['TotalPrecip'].isnull(), 'TotalPrecip'] = 0\n",
    "    df['MaxTemp'] = np.where(df['MaxTemp'].isnull(),\n",
    "                             df['MeanTemp'], df['MaxTemp'])\n",
    "    df['MinTemp'] = np.where(df['MinTemp'].isnull(),\n",
    "                             df['MeanTemp'], df['MinTemp'])\n",
    "\n",
    "    df[['ClimateID', 'Date']] = df[['ClimateID', 'Date']].astype(str)\n",
    "    df[['Year', 'Month', 'Day']] = df[['Year', 'Month', 'Day']].astype(int)\n",
    "    df[['MaxTemp', 'MinTemp', 'MeanTemp', 'TotalRain', 'TotalSnow', 'TotalPrecip', 'SnowOnGrnd']] = df[[\n",
    "        'MaxTemp', 'MinTemp', 'MeanTemp', 'TotalRain', 'TotalSnow', 'TotalPrecip', 'SnowOnGrnd']].astype(float)\n",
    "\n",
    "    # we try a db push, but if it fails, we place the data in a csv file\n",
    "    # try:\n",
    "    push_data(df)\n",
    "    db_con.execute(\n",
    "        \"UPDATE public.\\\"lgFireStationsTen\\\" SET \\\"dataAvailable\\\" = True WHERE \\\"ClimateID\\\" like {};\".format(stationID))\n",
    "    # except:\n",
    "    #     df.to_csv(\"Failed/\" + str(df.iloc[0, 0]) +\n",
    "    #             \"_data_failed_dbpush.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.UndefinedColumn) column \"3070043\" does not exist\nLINE 1: ...SET \"dataAvailable\" = True WHERE \"ClimateID\" like \"3070043\";\n                                                             ^\n\n[SQL: UPDATE public.\"lgFireStationsTen\" SET \"dataAvailable\" = True WHERE \"ClimateID\" like \"3070043\";]\n(Background on this error at: https://sqlalche.me/e/14/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedColumn\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py:1900\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1899\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1900\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1901\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1902\u001b[0m         )\n\u001b[1;32m   1904\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py:736\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 736\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mUndefinedColumn\u001b[0m: column \"3070043\" does not exist\nLINE 1: ...SET \"dataAvailable\" = True WHERE \"ClimateID\" like \"3070043\";\n                                                             ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m df\u001b[39m.\u001b[39mempty:\n\u001b[0;32m---> 21\u001b[0m     dataProcessA(df, stationID)\n\u001b[1;32m     22\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     db_con\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m     24\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUPDATE public.\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mlgFireStationsTen\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m SET \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mdataAvailable\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m = False WHERE \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mClimateID\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m like \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(stationID))\n",
      "Cell \u001b[0;32mIn [34], line 43\u001b[0m, in \u001b[0;36mdataProcessA\u001b[0;34m(df, stationID)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m# we try a db push, but if it fails, we place the data in a csv file\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m# try:\u001b[39;00m\n\u001b[1;32m     42\u001b[0m push_data(df)\n\u001b[0;32m---> 43\u001b[0m db_con\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m     44\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mUPDATE public.\u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39mlgFireStationsTen\u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m SET \u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39mdataAvailable\u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m = True WHERE \u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39mClimateID\u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m like \u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m{}\u001b[39;49;00m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m;\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(stationID))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py:1365\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(statement, util\u001b[39m.\u001b[39mstring_types):\n\u001b[1;32m   1357\u001b[0m     util\u001b[39m.\u001b[39mwarn_deprecated_20(\n\u001b[1;32m   1358\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a string to Connection.execute() is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1359\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated and will be removed in version 2.0.  Use the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdriver-level SQL string.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[0;32m-> 1365\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_driver_sql(\n\u001b[1;32m   1366\u001b[0m         statement,\n\u001b[1;32m   1367\u001b[0m         multiparams,\n\u001b[1;32m   1368\u001b[0m         params,\n\u001b[1;32m   1369\u001b[0m         _EMPTY_EXECUTION_OPTS,\n\u001b[1;32m   1370\u001b[0m         future\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1371\u001b[0m     )\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     meth \u001b[39m=\u001b[39m statement\u001b[39m.\u001b[39m_execute_on_connection\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py:1669\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         (\n\u001b[1;32m   1660\u001b[0m             statement,\n\u001b[1;32m   1661\u001b[0m             distilled_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1665\u001b[0m             statement, distilled_parameters, execution_options\n\u001b[1;32m   1666\u001b[0m         )\n\u001b[1;32m   1668\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[0;32m-> 1669\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1670\u001b[0m     dialect,\n\u001b[1;32m   1671\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_statement,\n\u001b[1;32m   1672\u001b[0m     statement,\n\u001b[1;32m   1673\u001b[0m     distilled_parameters,\n\u001b[1;32m   1674\u001b[0m     execution_options,\n\u001b[1;32m   1675\u001b[0m     statement,\n\u001b[1;32m   1676\u001b[0m     distilled_parameters,\n\u001b[1;32m   1677\u001b[0m )\n\u001b[1;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m future:\n\u001b[1;32m   1680\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py:1943\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1940\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1942\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1943\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1944\u001b[0m         e, statement, parameters, cursor, context\n\u001b[1;32m   1945\u001b[0m     )\n\u001b[1;32m   1947\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py:2124\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2122\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[1;32m   2123\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2124\u001b[0m     util\u001b[39m.\u001b[39;49mraise_(\n\u001b[1;32m   2125\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m], from_\u001b[39m=\u001b[39;49me\n\u001b[1;32m   2126\u001b[0m     )\n\u001b[1;32m   2127\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2128\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py:210\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    207\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[1;32m    209\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[1;32m    211\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py:1900\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1898\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1900\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1901\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1902\u001b[0m         )\n\u001b[1;32m   1904\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1905\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1906\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1907\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1912\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py:736\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 736\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (psycopg2.errors.UndefinedColumn) column \"3070043\" does not exist\nLINE 1: ...SET \"dataAvailable\" = True WHERE \"ClimateID\" like \"3070043\";\n                                                             ^\n\n[SQL: UPDATE public.\"lgFireStationsTen\" SET \"dataAvailable\" = True WHERE \"ClimateID\" like \"3070043\";]\n(Background on this error at: https://sqlalche.me/e/14/f405)"
     ]
    }
   ],
   "source": [
    "requester = cdr()\n",
    "\n",
    "provinces = {'brit': \"BC\", 'albe': \"AB\", 'sask': \"SK\", 'mani': \"MB\", 'onta': \"ON\", 'queb': \"QC\",\n",
    "             'nuna': \"NU\", 'yuko': \"YT\", 'nort': \"NT\", 'newf': \"NL\", 'prin': \"PE\", 'nova': \"NS\", 'new ': \"NB\"}\n",
    "\n",
    "# for each station, we will request the weather data for the years 2010 to 2022\n",
    "df = pd.DataFrame()\n",
    "for index, row in dfStations.iterrows():\n",
    "\n",
    "    if row['dataAvailable'] != True:\n",
    "\n",
    "        key = row['Province'].lower()[:4]\n",
    "        province = provinces[key]\n",
    "\n",
    "        if province == \"AB\" or province == \"SK\" or province == \"MB\" or province == \"YT\":\n",
    "            stationID = str(row['ClimateID'])\n",
    "            df = requester.get_data(province, stationID, 2010, 2022)\n",
    "            clear_output(wait=False)\n",
    "\n",
    "            if not df.empty:\n",
    "                dataProcessA(df, stationID)\n",
    "            else:\n",
    "                db_con.execute(\n",
    "                    \"UPDATE public.\\\"lgFireStationsTen\\\" SET \\\"dataAvailable\\\" = False WHERE \\\"ClimateID\\\" like {};\".format(stationID))\n",
    "\n",
    "        else:\n",
    "            print(\"Province not wanted: \" + province)\n",
    "\n",
    "    else:\n",
    "        print(\"Data for station \" + str(row['ClimateID']) + \" already exists.\")\n",
    "\n",
    "    print(\"Processed row \" + str(index) + \" of \" + str(len(dfStations)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
