{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install python-dotenv\n",
    "# %pip install seaborn\n",
    "# %pip install tensorflow_data_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pygeos as pg\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_data_validation as tfdv\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "# from datetime import datetime\n",
    "# from dotenv import load_dotenv\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely import wkt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following lines adjust the granularity of reporting.\n",
    "#pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "os.chdir('F:\\\\Uni Files\\\\4710\\\\4710 Project\\\\MLweatherForestFire')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGPDfromPD(df: pd.DataFrame, geomCol: str, crs: str = \"EPSG:3978\") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Convert a pandas dataframe to a geopandas dataframe\n",
    "    :param df: pandas dataframe\n",
    "    :param geomCol: name of the geometry column\n",
    "    :param crs: coordinate reference system\n",
    "    :return: geopandas dataframe\n",
    "    \"\"\"\n",
    "    if 'geom' in df.columns:\n",
    "        df.rename(columns={'geom': 'geometry'}, inplace=True)\n",
    "\n",
    "    df[geomCol] = df[geomCol].apply(wkt.loads)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geomCol, crs=crs)\n",
    "    return gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireWeatherTable = \"Data/FinalFeature.csv\"\n",
    "dfFireWeather = pd.read_csv(fireWeatherTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTRYID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SIZE_HA</th>\n",
       "      <th>SIZE_HA_BIN</th>\n",
       "      <th>ELEVATIONM</th>\n",
       "      <th>DIST_TO_WATER</th>\n",
       "      <th>DAYW</th>\n",
       "      <th>MAXTEMP</th>\n",
       "      <th>MEANHUMIDITY</th>\n",
       "      <th>MEANWINDSPEED</th>\n",
       "      <th>MAXWINDSPEED</th>\n",
       "      <th>TOTALPRECIP</th>\n",
       "      <th>LONG</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONGBIN</th>\n",
       "      <th>LATBIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1143.2</td>\n",
       "      <td>2009.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>16.7</td>\n",
       "      <td>10705.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>742.7</td>\n",
       "      <td>3881.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>61.2</td>\n",
       "      <td>8.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5375901.9</td>\n",
       "      <td>2375607.2</td>\n",
       "      <td>365.0</td>\n",
       "      <td>384.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1439.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29415.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>513.4</td>\n",
       "      <td>4094.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>139093.0</td>\n",
       "      <td>204885.0</td>\n",
       "      <td>111.1</td>\n",
       "      <td>97.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>283.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>201.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4918132.3</td>\n",
       "      <td>1567321.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>522.8</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>704.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1114.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5267895.2</td>\n",
       "      <td>2246671.4</td>\n",
       "      <td>278.5</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>753.5</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2070.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2467.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5379082.5</td>\n",
       "      <td>2392909.7</td>\n",
       "      <td>367.5</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1539.2</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7250.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>5318.9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>68.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5493470.9</td>\n",
       "      <td>2524069.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10650.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>476376.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3668.0</td>\n",
       "      <td>29418.8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>30.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>5632110.7</td>\n",
       "      <td>2763468.2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>569.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ENTRYID   YEAR  MONTH   DAY  SIZE_HA  SIZE_HA_BIN  ELEVATIONM  \\\n",
       "count    836.0  836.0  836.0 836.0    836.0        836.0       836.0   \n",
       "mean    1143.2 2009.5    6.4  16.7  10705.3          1.7       742.7   \n",
       "std     1439.2    5.3    1.1   9.0  29415.9          1.1       513.4   \n",
       "min      283.0 2000.0    1.0   2.0    201.8          0.0       225.0   \n",
       "25%      522.8 2005.0    6.0   8.0    704.4          1.0       434.0   \n",
       "50%      753.5 2010.0    6.0  17.0   2070.2          2.0       496.0   \n",
       "75%     1539.2 2015.0    7.0  25.0   7250.0          3.0      1161.0   \n",
       "max    10650.0 2020.0   10.0  31.0 476376.8          3.0      3668.0   \n",
       "\n",
       "       DIST_TO_WATER  DAYW  MAXTEMP  MEANHUMIDITY  MEANWINDSPEED  \\\n",
       "count          836.0 836.0    836.0         836.0          836.0   \n",
       "mean          3881.6  15.7     23.1          61.2            8.3   \n",
       "std           4094.2   9.0      6.4          12.1            3.4   \n",
       "min              0.0   1.0     -6.2          28.0            2.1   \n",
       "25%           1114.6   7.0     21.1          53.0            5.9   \n",
       "50%           2467.7  16.0     24.4          61.0            7.5   \n",
       "75%           5318.9  24.0     26.9          68.6           10.2   \n",
       "max          29418.8  30.0     34.9          96.9           30.1   \n",
       "\n",
       "       MAXWINDSPEED  TOTALPRECIP      LONG       LAT  LONGBIN  LATBIN  \n",
       "count         836.0        836.0     836.0     836.0    836.0   836.0  \n",
       "mean           16.2          0.2 5375901.9 2375607.2    365.0   384.7  \n",
       "std             5.9          1.5  139093.0  204885.0    111.1    97.6  \n",
       "min             4.0          0.0 4918132.3 1567321.0      0.0     0.0  \n",
       "25%            11.0          0.0 5267895.2 2246671.4    278.5   323.0  \n",
       "50%            16.0          0.0 5379082.5 2392909.7    367.5   393.0  \n",
       "75%            20.0          0.0 5493470.9 2524069.0    459.0   455.0  \n",
       "max            37.0         20.8 5632110.7 2763468.2    569.0   569.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEval = dfFireWeather\n",
    "dfEval.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L    209\n",
       "M    209\n",
       "H    209\n",
       "E    209\n",
       "Name: SIZE_HA_BIN, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log transform SIZE_HA\n",
    "dfEval['SIZE_HA'] = np.log(dfEval['SIZE_HA'])\n",
    "\n",
    "# binning SIZE_HA into 4 categories L M H E in SIZE_HA_BIN\n",
    "dfEval['SIZE_HA_BIN'] = pd.qcut(dfEval['SIZE_HA'], 4, labels=['L', 'M', 'H', 'E'])\n",
    "\n",
    "# count the number of fires in each SIZE_HA_BIN\n",
    "dfEval['SIZE_HA_BIN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ENTRYID   YEAR  MONTH   DAY  SIZE_HA  ELEVATIONM  DIST_TO_WATER  DAYW  \\\n",
      "count    836.0  836.0  836.0 836.0    836.0       836.0          836.0 836.0   \n",
      "mean    1143.2 2009.5    6.4  16.7      2.0       742.7         3881.6  15.7   \n",
      "std     1439.2    5.3    1.1   9.0      0.2       513.4         4094.2   9.0   \n",
      "min      283.0 2000.0    1.0   2.0      1.7       225.0            0.0   1.0   \n",
      "25%      522.8 2005.0    6.0   8.0      1.9       434.0         1114.6   7.0   \n",
      "50%      753.5 2010.0    6.0  17.0      2.0       496.0         2467.7  16.0   \n",
      "75%     1539.2 2015.0    7.0  25.0      2.2      1161.0         5318.9  24.0   \n",
      "max    10650.0 2020.0   10.0  31.0      2.6      3668.0        29418.8  30.0   \n",
      "\n",
      "       MAXTEMP  MEANHUMIDITY  MEANWINDSPEED  MAXWINDSPEED  TOTALPRECIP  \\\n",
      "count    836.0         836.0          836.0         836.0        836.0   \n",
      "mean      23.1          61.2            8.3          16.2          0.2   \n",
      "std        6.4          12.1            3.4           5.9          1.5   \n",
      "min       -6.2          28.0            2.1           4.0          0.0   \n",
      "25%       21.1          53.0            5.9          11.0          0.0   \n",
      "50%       24.4          61.0            7.5          16.0          0.0   \n",
      "75%       26.9          68.6           10.2          20.0          0.0   \n",
      "max       34.9          96.9           30.1          37.0         20.8   \n",
      "\n",
      "           LONG       LAT  LONGBIN  LATBIN  \n",
      "count     836.0     836.0    836.0   836.0  \n",
      "mean  5375901.9 2375607.2    365.0   384.7  \n",
      "std    139093.0  204885.0    111.1    97.6  \n",
      "min   4918132.3 1567321.0      0.0     0.0  \n",
      "25%   5267895.2 2246671.4    278.5   323.0  \n",
      "50%   5379082.5 2392909.7    367.5   393.0  \n",
      "75%   5493470.9 2524069.0    459.0   455.0  \n",
      "max   5632110.7 2763468.2    569.0   569.0  \n"
     ]
    }
   ],
   "source": [
    "# print rows with nan\n",
    "print(dfEval.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store our random selection, run once\n",
    "# randomTrain = \"RandomTrain\"\n",
    "# dfTrain.to_sql(randomTrain, db_push_con, if_exists='replace', index=False)\n",
    "\n",
    "# randomTest = \"RandomTest\"\n",
    "# dfTest.to_sql(randomTest, db_push_con, if_exists='replace', index=False)\n",
    "\n",
    "# randomValidate = \"RandomValidate\"\n",
    "# dfValidate.to_sql(randomValidate, db_push_con, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.inspection import DecisionBoundaryDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENTRYID', 'FIRE_ID', 'FIRENAME', 'YEAR', 'MONTH', 'DAY', 'REP_DATE',\n",
       "       'SIZE_HA', 'SIZE_HA_BIN', 'GEOM', 'ELEVATIONM', 'DIST_TO_WATER',\n",
       "       'CLIMATEID', 'PROVINCECODE', 'DAYW', 'MAXTEMP', 'MEANHUMIDITY',\n",
       "       'MEANWINDSPEED', 'MAXWINDSPEED', 'TOTALPRECIP', 'RAIN', 'LONG', 'LAT',\n",
       "       'LONGBIN', 'LATBIN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEval.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrim = dfEval.copy(deep=True)\n",
    "\n",
    "# edit this\n",
    "dfTrim = dfTrim.drop(columns={'ENTRYID', 'FIRE_ID', 'FIRENAME', 'GEOM', 'CLIMATEID', 'PROVINCECODE',\n",
    "                              'TOTALPRECIP', 'LONG', 'LAT', 'REP_DATE', 'SIZE_HA'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace size_ha_bin 0 1 2 3 with L M H E\n",
    "\n",
    "# dfTrim['SIZE_HA_BIN'] = dfTrim['SIZE_HA_BIN'].astype(str).replace('0', 'L')\n",
    "# dfTrim['SIZE_HA_BIN'] = dfTrim['SIZE_HA_BIN'].astype(str).replace('1', 'M')\n",
    "# dfTrim['SIZE_HA_BIN'] = dfTrim['SIZE_HA_BIN'].astype(str).replace('2', 'H')\n",
    "# dfTrim['SIZE_HA_BIN'] = dfTrim['SIZE_HA_BIN'].astype(str).replace('3', 'E')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 6 years from 2010-2019 for training\n",
    "dfTrain = dfTrim[dfTrim['YEAR'].isin(\n",
    "    [2010, 2011, 2012, 2013, 2014, 2015, 2016])].drop(columns={'SIZE_HA_BIN'})\n",
    "dfTest = dfTrim[dfTrim['YEAR'].isin([2017, 2018, 2019, 2020])].drop(\n",
    "    columns={'SIZE_HA_BIN'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # regularize y values using z score\n",
    "    df = (df - df.mean()) / df.std()\n",
    "    # set max value to 3 zscore\n",
    "    df[df > 3] = 3\n",
    "    # set min value to -3 zscore\n",
    "    df[df < -3] = -3\n",
    "\n",
    "    # shift the wole train set to be positive\n",
    "    df = df + 3\n",
    "\n",
    "    # return dataframe list of means and stds\n",
    "    return df, df.mean(), df.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainScaled, dfMeans, dfStdevs = scaleData(dfTrain.copy(deep=True))\n",
    "dfTrainScaled['YEAR'] = dfTrain['YEAR']\n",
    "dfTrainScaled['SIZE_HA_BIN'] = dfTrim[dfTrim['YEAR'].isin(\n",
    "    [2010, 2011, 2012, 2013, 2014, 2015, 2016])]['SIZE_HA_BIN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR             357\n",
      "MONTH            357\n",
      "DAY              357\n",
      "ELEVATIONM       357\n",
      "DIST_TO_WATER    357\n",
      "DAYW             357\n",
      "MAXTEMP          357\n",
      "MEANHUMIDITY     357\n",
      "MEANWINDSPEED    357\n",
      "MAXWINDSPEED     357\n",
      "RAIN             357\n",
      "LONGBIN          357\n",
      "LATBIN           357\n",
      "SIZE_HA_BIN      357\n",
      "dtype: int64\n",
      "0\n",
      "YEAR                int64\n",
      "MONTH             float64\n",
      "DAY               float64\n",
      "ELEVATIONM        float64\n",
      "DIST_TO_WATER     float64\n",
      "DAYW              float64\n",
      "MAXTEMP           float64\n",
      "MEANHUMIDITY      float64\n",
      "MEANWINDSPEED     float64\n",
      "MAXWINDSPEED      float64\n",
      "RAIN              float64\n",
      "LONGBIN           float64\n",
      "LATBIN            float64\n",
      "SIZE_HA_BIN      category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(dfTrainScaled.count())\n",
    "print(dfTrainScaled.isna().sum().sum())\n",
    "print(dfTrainScaled.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        YEAR  MONTH   DAY  ELEVATIONM  DIST_TO_WATER  DAYW  MAXTEMP  \\\n",
      "count  357.0  357.0 357.0       357.0          357.0 357.0    357.0   \n",
      "mean  2012.9    3.0   3.0         3.0            3.0   3.0      3.0   \n",
      "std      2.1    1.0   1.0         1.0            0.9   1.0      0.9   \n",
      "min   2010.0    0.4   1.4         2.0            2.1   1.4      0.0   \n",
      "25%   2011.0    2.5   2.0         2.4            2.3   2.0      2.6   \n",
      "50%   2013.0    3.5   3.1         2.5            2.6   3.1      3.2   \n",
      "75%   2015.0    3.5   3.9         2.8            3.3   3.9      3.6   \n",
      "max   2016.0    6.0   4.5         6.0            6.0   4.5      5.1   \n",
      "\n",
      "       MEANHUMIDITY  MEANWINDSPEED  MAXWINDSPEED  RAIN  LONGBIN  LATBIN  \n",
      "count         357.0          357.0         357.0 357.0    357.0   357.0  \n",
      "mean            3.0            3.0           3.0   3.0      3.0     3.0  \n",
      "std             1.0            0.9           1.0   1.0      1.0     1.0  \n",
      "min             0.2            1.4           1.2   2.5      0.5     0.0  \n",
      "25%             2.4            2.4           2.3   2.5      2.2     2.3  \n",
      "50%             3.0            2.8           3.0   2.5      2.9     3.0  \n",
      "75%             3.6            3.5           3.8   2.5      3.9     3.7  \n",
      "max             5.7            6.0           6.0   5.1      4.9     5.1  \n"
     ]
    }
   ],
   "source": [
    "print(dfTrainScaled.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1  # SVM regularization parameter\n",
    "\n",
    "model1 = svm.SVC(kernel=\"linear\", C=C, decision_function_shape='ovo')\n",
    "model2 = svm.LinearSVC(C=C, max_iter=10000)\n",
    "model3 = svm.SVC(kernel=\"rbf\", gamma=0.7, C=C, decision_function_shape='ovo')\n",
    "model4 = svm.SVC(kernel=\"poly\", degree=3, gamma=\"auto\",\n",
    "                 C=C, decision_function_shape='ovo')\n",
    "model5 = svm.SVC(kernel=\"sigmoid\", gamma=\"auto\", C=C, decision_function_shape='ovo')\n",
    "\n",
    "# random forest\n",
    "model6 = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "model7 = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=0)\n",
    "model8 = RandomForestClassifier(n_estimators=100, max_depth=50, random_state=0)\n",
    "model9 = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=0)\n",
    "\n",
    "dfFeatures = dfTrainScaled.drop(['SIZE_HA_BIN', 'YEAR'], axis=1)\n",
    "dfLabel = dfTrainScaled['SIZE_HA_BIN']\n",
    "\n",
    "model1 = model1.fit(dfFeatures, dfLabel)\n",
    "model2 = model2.fit(dfFeatures, dfLabel)\n",
    "model3 = model3.fit(dfFeatures, dfLabel)\n",
    "model4 = model4.fit(dfFeatures, dfLabel)\n",
    "model5 = model5.fit(dfFeatures, dfLabel)\n",
    "model6 = model6.fit(dfFeatures, dfLabel)\n",
    "model7 = model7.fit(dfFeatures, dfLabel)\n",
    "model8 = model8.fit(dfFeatures, dfLabel)\n",
    "model9 = model9.fit(dfFeatures, dfLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale test data using the same means and stds\n",
    "dfTestScaled = (dfTest - dfMeans) / dfStdevs\n",
    "\n",
    "# shift the wole test set to be positive\n",
    "dfTestScaled = dfTestScaled + 3\n",
    "\n",
    "# add year column back\n",
    "dfTestScaled['YEAR'] = dfTest['YEAR']\n",
    "dfTestScaled['SIZE_HA_BIN'] = dfTrim[dfTrim['YEAR'].isin(\n",
    "    [2017, 2018, 2019, 2020])]['SIZE_HA_BIN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     YEAR  MONTH  DAY  ELEVATIONM  DIST_TO_WATER  DAYW  MAXTEMP  MEANHUMIDITY  \\\n",
      "737  2017    8.1  5.0       378.6         6284.5   4.0     28.3          61.3   \n",
      "738  2017    7.1 21.0      1683.8          625.3  20.0     19.9          54.8   \n",
      "739  2017    8.1  5.0       450.5          870.8   4.0     26.0          74.2   \n",
      "740  2017    8.1 12.0       454.6         7020.1  11.0     28.8          72.9   \n",
      "741  2017    7.1 27.0       409.0         1151.0  26.0     28.6          70.5   \n",
      "\n",
      "     MEANWINDSPEED  MAXWINDSPEED  RAIN  LONGBIN  LATBIN SIZE_HA_BIN  \n",
      "737            7.1          11.2  -0.0    470.0   486.8           M  \n",
      "738            7.1          10.1  -0.0    352.0   543.5           H  \n",
      "739            3.5           8.1  -0.0    536.0   454.4           L  \n",
      "740            3.0           9.1  -0.0    546.0   451.4           M  \n",
      "741            5.6          10.1  -0.0    503.0   502.0           L  \n"
     ]
    }
   ],
   "source": [
    "print(dfTestScaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestFeatures = dfTestScaled.drop(['SIZE_HA_BIN', 'YEAR'], axis=1)\n",
    "\n",
    "# predict on test data\n",
    "dfTestScaled['PREDICTED_SIZE_HA_BIN1'] = model1.predict(dfTestFeatures)\n",
    "dfTestScaled['PREDICTED_SIZE_HA_BIN2'] = model2.predict(dfTestFeatures)\n",
    "dfTestScaled['PREDICTED_SIZE_HA_BIN3'] = model3.predict(dfTestFeatures)\n",
    "dfTestScaled['PREDICTED_SIZE_HA_BIN4'] = model4.predict(dfTestFeatures)\n",
    "dfTestScaled['PREDICTED_SIZE_HA_BIN5'] = model5.predict(dfTestFeatures)\n",
    "dfTestScaled['PREDICTED_SIZE_HA_BIN6'] = model6.predict(dfTestFeatures)\n",
    "dfTestScaled['PREDICTED_SIZE_HA_BIN7'] = model7.predict(dfTestFeatures)\n",
    "dfTestScaled['PREDICTED_SIZE_HA_BIN8'] = model8.predict(dfTestFeatures)\n",
    "dfTestScaled['PREDICTED_SIZE_HA_BIN9'] = model9.predict(dfTestFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show roc curve\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # dashed diagonal\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show precision recall curve\n",
    "def plot_precision_recall_curve(precision, recall, label=None):\n",
    "    plt.plot(recall, precision, linewidth=2, label=label)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show accuracy, precision, recall, f1 score\n",
    "# def show_metrics(y_test, y_pred, labels):\n",
    "#     print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "#     print(\"Precision: \", precision_score(\n",
    "#         y_test, y_pred, labels=labels, average='micro'))\n",
    "#     print(\"Recall: \", recall_score(\n",
    "#         y_test, y_pred, labels=labels, average='micro'))\n",
    "#     print(\"F1 Score: \", f1_score(y_test, y_pred, labels=labels, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show accuracy, precision, recall, f1 score\n",
    "def show_metrics(y_test, y_pred):\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision: \", precision_score(\n",
    "        y_test, y_pred, average='micro'))\n",
    "    print(\"Recall: \", recall_score(\n",
    "        y_test, y_pred, average='micro'))\n",
    "    print(\"F1 Score: \", f1_score(y_test, y_pred, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  1\n",
      "Accuracy:  0.2073170731707317\n",
      "Precision:  0.2073170731707317\n",
      "Recall:  0.2073170731707317\n",
      "F1 Score:  0.2073170731707317\n",
      "Model  2\n",
      "Accuracy:  0.18292682926829268\n",
      "Precision:  0.18292682926829268\n",
      "Recall:  0.18292682926829268\n",
      "F1 Score:  0.18292682926829268\n",
      "Model  3\n",
      "Accuracy:  0.18292682926829268\n",
      "Precision:  0.18292682926829268\n",
      "Recall:  0.18292682926829268\n",
      "F1 Score:  0.18292682926829268\n",
      "Model  4\n",
      "Accuracy:  0.24390243902439024\n",
      "Precision:  0.24390243902439024\n",
      "Recall:  0.24390243902439024\n",
      "F1 Score:  0.24390243902439024\n",
      "Model  5\n",
      "Accuracy:  0.18292682926829268\n",
      "Precision:  0.18292682926829268\n",
      "Recall:  0.18292682926829268\n",
      "F1 Score:  0.18292682926829268\n",
      "Model  6\n",
      "Accuracy:  0.2682926829268293\n",
      "Precision:  0.2682926829268293\n",
      "Recall:  0.2682926829268293\n",
      "F1 Score:  0.2682926829268293\n",
      "Model  7\n",
      "Accuracy:  0.25609756097560976\n",
      "Precision:  0.25609756097560976\n",
      "Recall:  0.25609756097560976\n",
      "F1 Score:  0.25609756097560976\n",
      "Model  8\n",
      "Accuracy:  0.25609756097560976\n",
      "Precision:  0.25609756097560976\n",
      "Recall:  0.25609756097560976\n",
      "F1 Score:  0.25609756097560976\n",
      "Model  9\n",
      "Accuracy:  0.25609756097560976\n",
      "Precision:  0.25609756097560976\n",
      "Recall:  0.25609756097560976\n",
      "F1 Score:  0.25609756097560976\n"
     ]
    }
   ],
   "source": [
    "labels = ['L', 'M', 'H', 'E']\n",
    "# show metrics for each model\n",
    "for i in range(1, 10):\n",
    "    print(\"Model \", i)\n",
    "    show_metrics(dfTestScaled['SIZE_HA_BIN'],\n",
    "                 dfTestScaled['PREDICTED_SIZE_HA_BIN' + str(i)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_295260\\831620.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfTestScaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mf:\\Programs\\Miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Programs\\Miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3718\u001b[0m         )\n\u001b[0;32m   3719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3720\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3721\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3722\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Programs\\Miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Programs\\Miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         )\n\u001b[1;32m-> 1189\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Programs\\Miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \"\"\"\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Programs\\Miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'test.csv'"
     ]
    }
   ],
   "source": [
    "dfTestScaled.to_csv('test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef7e3ad1fe0a4a5293cd6ca311ffca45c667fb34d948e973384e8d54f12a93f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
