{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install python-dotenv\n",
    "# %pip install seaborn\n",
    "# %pip install tensorflow_data_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pygeos as pg\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following lines adjust the granularity of reporting.\n",
    "#pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "os.chdir('F:\\\\Uni Files\\\\4710\\\\4710 Project\\\\MLweatherForestFire')\n",
    "NULLFLAG = -9999\n",
    "ONEDAY = 24 * 60 * 60\n",
    "WEEK = 7 * ONEDAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENTRYID', 'FIRE_ID', 'FIRENAME', 'YEAR', 'MONTH', 'DAY', 'REP_DATE',\n",
       "       'SIZE_HA', 'SIZE_HA_BIN', 'GEOM', 'ELEVATIONM', 'DIST_TO_WATER',\n",
       "       'CLIMATEID', 'PROVINCECODE', 'DAYW', 'MAXTEMP', 'MEANHUMIDITY',\n",
       "       'MEANWINDSPEED', 'MAXWINDSPEED', 'TOTALPRECIP', 'RAIN', 'LONG', 'LAT',\n",
       "       'LONGBIN', 'LATBIN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireWeatherTable = \"Data/FinalFeature.csv\"\n",
    "dfFireWeather = pd.read_csv(fireWeatherTable)\n",
    "dfFireWeather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Red\\AppData\\Local\\Temp\\ipykernel_457804\\2291072772.py:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfWeather = pd.read_csv(dailyWeather)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ClimateID', 'ProvinceCode', 'Year', 'Month', 'Day', 'MeanTemp',\n",
       "       'MinTemp', 'MaxTemp', 'MeanDewPoint', 'MinDewPoint', 'MaxDewPoint',\n",
       "       'MeanHumidity', 'MinHumidity', 'MaxHumidity', 'MeanPressure',\n",
       "       'MinPressure', 'MaxPressure', 'MeanWindSpeed', 'MinWindSpeed',\n",
       "       'MaxWindSpeed', 'MeanWindChill', 'MinWindChill', 'MaxWindChill',\n",
       "       'TotalPrecip', 'MeanWindDirection'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyWeather = \"Data/WeatherDataHourlyAggDaily.csv\"\n",
    "dfWeather = pd.read_csv(dailyWeather)\n",
    "dfWeather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeather.astype({'ClimateID': 'str', 'ProvinceCode': 'str', \n",
    "                'Year': 'int', 'Month': 'int', 'Day': 'int',\n",
    "                'MeanTemp': 'float', 'MinTemp': 'float', 'MaxTemp': 'float',\n",
    "                'MeanDewPoint': 'float', 'MinDewPoint': 'float', 'MaxDewPoint': 'float',\n",
    "                'MeanHumidity': 'float', 'MinHumidity': 'float', 'MaxHumidity': 'float',\n",
    "                'MeanPressure': 'float', 'MinPressure': 'float', 'MaxPressure': 'float',\n",
    "                'MeanWindSpeed': 'float', 'MinWindSpeed': 'float', 'MaxWindSpeed': 'float',\n",
    "                'MeanWindChill': 'float', 'MinWindChill': 'float', 'MaxWindChill': 'float',\n",
    "                'TotalPrecip': 'float', 'MeanWindDirection': 'float'}, copy=False)\n",
    "dfWeather.drop(columns=['MeanTemp', 'MinTemp', 'MeanDewPoint', 'MinDewPoint', 'MaxDewPoint',\n",
    "                    'MinHumidity', 'MaxHumidity', 'MeanPressure', 'MinPressure',\n",
    "                    'MaxPressure', 'MinWindSpeed', 'MeanWindChill', 'MinWindChill', 'MaxWindChill',\n",
    "                    'MeanWindDirection' ], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sums of max temp humidity days with precipitation in time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeatherDaily = dfWeather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add utc from year month day\n",
    "dfWeatherDaily['utc'] = pd.to_datetime(dfWeatherDaily[['Year', 'Month', 'Day']]).astype('int64')\n",
    "dfFireWeather['utc'] = pd.to_datetime(dfFireWeather[['YEAR', 'MONTH', 'DAY']]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClimateID        89909\n",
       "ProvinceCode     89909\n",
       "Year             89909\n",
       "Month            89909\n",
       "Day              89909\n",
       "MaxTemp          89796\n",
       "MeanHumidity     88632\n",
       "MeanWindSpeed    88926\n",
       "MaxWindSpeed     88926\n",
       "TotalPrecip      89909\n",
       "utc              89909\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWeatherDaily.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClimateID</th>\n",
       "      <th>ProvinceCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MeanHumidity</th>\n",
       "      <th>MeanWindSpeed</th>\n",
       "      <th>MaxWindSpeed</th>\n",
       "      <th>TotalPrecip</th>\n",
       "      <th>utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5658</th>\n",
       "      <td>2202201</td>\n",
       "      <td>NT</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>22.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12647</th>\n",
       "      <td>2202202</td>\n",
       "      <td>NT</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>22.7</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27362</th>\n",
       "      <td>4060983</td>\n",
       "      <td>SK</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>22.7</td>\n",
       "      <td>39.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30468</th>\n",
       "      <td>4060984</td>\n",
       "      <td>SK</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>22.8</td>\n",
       "      <td>31.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32470</th>\n",
       "      <td>4060988</td>\n",
       "      <td>SK</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>22.8</td>\n",
       "      <td>36.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35073</th>\n",
       "      <td>4061620</td>\n",
       "      <td>SK</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>11.4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46457</th>\n",
       "      <td>4063605</td>\n",
       "      <td>SK</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>20.3</td>\n",
       "      <td>54.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54199</th>\n",
       "      <td>4064149</td>\n",
       "      <td>SK</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>21.5</td>\n",
       "      <td>52.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62318</th>\n",
       "      <td>4064155</td>\n",
       "      <td>SK</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>22.2</td>\n",
       "      <td>53.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70174</th>\n",
       "      <td>4067655</td>\n",
       "      <td>SK</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>13.6</td>\n",
       "      <td>66.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77932</th>\n",
       "      <td>406QLD0</td>\n",
       "      <td>SK</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>19.9</td>\n",
       "      <td>45.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81878</th>\n",
       "      <td>5061645</td>\n",
       "      <td>MB</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>12.8</td>\n",
       "      <td>75.9</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87559</th>\n",
       "      <td>5061649</td>\n",
       "      <td>MB</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>12.6</td>\n",
       "      <td>72.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430179200000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ClimateID ProvinceCode  Year  Month  Day  MaxTemp  MeanHumidity  \\\n",
       "5658    2202201           NT  2015      4   28     22.1          43.8   \n",
       "12647   2202202           NT  2015      4   28     22.7          42.0   \n",
       "27362   4060983           SK  2015      4   28     22.7          39.5   \n",
       "30468   4060984           SK  2015      4   28     22.8          31.8   \n",
       "32470   4060988           SK  2015      4   28     22.8          36.5   \n",
       "35073   4061620           SK  2015      4   28     11.4          68.0   \n",
       "46457   4063605           SK  2015      4   28     20.3          54.9   \n",
       "54199   4064149           SK  2015      4   28     21.5          52.2   \n",
       "62318   4064155           SK  2015      4   28     22.2          53.2   \n",
       "70174   4067655           SK  2015      4   28     13.6          66.7   \n",
       "77932   406QLD0           SK  2015      4   28     19.9          45.8   \n",
       "81878   5061645           MB  2015      4   28     12.8          75.9   \n",
       "87559   5061649           MB  2015      4   28     12.6          72.1   \n",
       "\n",
       "       MeanWindSpeed  MaxWindSpeed  TotalPrecip                  utc  \n",
       "5658            11.1          22.0          0.0  1430179200000000000  \n",
       "12647            7.6          14.0          0.0  1430179200000000000  \n",
       "27362            8.5          17.0          1.3  1430179200000000000  \n",
       "30468           12.6          22.0          0.0  1430179200000000000  \n",
       "32470           12.0          22.0          0.0  1430179200000000000  \n",
       "35073           12.0          19.0          0.0  1430179200000000000  \n",
       "46457            6.0           8.0          0.0  1430179200000000000  \n",
       "54199            7.2          14.0          0.0  1430179200000000000  \n",
       "62318            8.1          18.0          0.0  1430179200000000000  \n",
       "70174            4.6           9.0          0.0  1430179200000000000  \n",
       "77932            7.0          12.0          0.0  1430179200000000000  \n",
       "81878           15.1          26.0          0.0  1430179200000000000  \n",
       "87559           10.2          16.0          0.0  1430179200000000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show weather 2015 4 28\n",
    "dfWeatherDaily[(dfWeatherDaily['Year'] == 2015) & (dfWeatherDaily['Month'] == 4) & (dfWeatherDaily['Day'] == 28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClimateID        274\n",
       "ProvinceCode     274\n",
       "Year             274\n",
       "Month            274\n",
       "Day              274\n",
       "MaxTemp          274\n",
       "MeanHumidity     269\n",
       "MeanWindSpeed    268\n",
       "MaxWindSpeed     268\n",
       "TotalPrecip      274\n",
       "utc              274\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count rows with MaxTemp 0\n",
    "dfWeatherDaily[dfWeatherDaily['MaxTemp'] == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFWEW = dfFireWeather.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 7 day sum max temp column, 7 day sum humidity column, 7 day sum precip column\n",
    "for index, row in dfFWEW.iterrows():\n",
    "    fireDate = datetime(row['YEAR'], row['MONTH'], row['DAY'])\n",
    "    maxTemps = []\n",
    "    humidities = []\n",
    "    windSpeeds = []\n",
    "    rainBool = False\n",
    "\n",
    "    for i in range(7):\n",
    "        day = fireDate - timedelta(days=i)\n",
    "        dayWeather = dfWeatherDaily.loc[(dfWeatherDaily['Year'] == day.year) & (dfWeatherDaily['Month'] == day.month) & (dfWeatherDaily['Day'] == day.day)]\n",
    "        if dayWeather.empty:\n",
    "            maxTemps.append(0)\n",
    "            humidities.append(0)\n",
    "            windSpeeds.append(0)\n",
    "        else:\n",
    "            maxTemps.append(dayWeather['MaxTemp'].max())\n",
    "            humidities.append(dayWeather['MeanHumidity'].mean())\n",
    "            windSpeeds.append(dayWeather['MeanWindSpeed'].mean())\n",
    "            if dayWeather['TotalPrecip'].values[0] > 0:\n",
    "                rainBool = True\n",
    "\n",
    "    dfFWEW.at[index, '7daySumMaxTemp'] = sum(maxTemps)\n",
    "    dfFWEW.at[index, '7daySumHumidity'] = sum(humidities)\n",
    "    dfFWEW.at[index, '7daySumWindSpeed'] = sum(windSpeeds)\n",
    "    # true if any day > 0\n",
    "    dfFWEW.at[index, '7dayRain'] = rainBool\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENTRYID             836\n",
       "FIRE_ID             836\n",
       "FIRENAME            836\n",
       "YEAR                836\n",
       "MONTH               836\n",
       "DAY                 836\n",
       "REP_DATE            836\n",
       "SIZE_HA             836\n",
       "SIZE_HA_BIN         836\n",
       "GEOM                836\n",
       "ELEVATIONM          836\n",
       "DIST_TO_WATER       836\n",
       "CLIMATEID           836\n",
       "PROVINCECODE        836\n",
       "DAYW                836\n",
       "MAXTEMP             836\n",
       "MEANHUMIDITY        836\n",
       "MEANWINDSPEED       836\n",
       "MAXWINDSPEED        836\n",
       "TOTALPRECIP         836\n",
       "RAIN                836\n",
       "LONG                836\n",
       "LAT                 836\n",
       "LONGBIN             836\n",
       "LATBIN              836\n",
       "utc                 836\n",
       "7daySumMaxTemp      836\n",
       "7daySumHumidity     836\n",
       "7daySumWindSpeed    836\n",
       "7dayRain            836\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFWEW.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENTRYID             0\n",
       "FIRE_ID             0\n",
       "FIRENAME            0\n",
       "YEAR                0\n",
       "MONTH               0\n",
       "DAY                 0\n",
       "REP_DATE            0\n",
       "SIZE_HA             0\n",
       "SIZE_HA_BIN         0\n",
       "GEOM                0\n",
       "ELEVATIONM          0\n",
       "DIST_TO_WATER       0\n",
       "CLIMATEID           0\n",
       "PROVINCECODE        0\n",
       "DAYW                0\n",
       "MAXTEMP             0\n",
       "MEANHUMIDITY        0\n",
       "MEANWINDSPEED       0\n",
       "MAXWINDSPEED        0\n",
       "TOTALPRECIP         0\n",
       "RAIN                0\n",
       "LONG                0\n",
       "LAT                 0\n",
       "LONGBIN             0\n",
       "LATBIN              0\n",
       "utc                 0\n",
       "7daySumMaxTemp      0\n",
       "7daySumHumidity     0\n",
       "7daySumWindSpeed    0\n",
       "7dayRain            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFWEW[dfFWEW['7daySumMaxTemp'] == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfFWEW.count())\n",
    "print(dfFWEW.describe())\n",
    "print(dfFWEW.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 14 day sum max temp column, 14 day sum humidity column, 14 day sum precip column\n",
    "for index, row in dfFWEW.iterrows():\n",
    "    fireDate = datetime(row['YEAR'], row['MONTH'], row['DAY'])\n",
    "    maxTemps = []\n",
    "    humidities = []\n",
    "    windSpeeds = []\n",
    "    rainBool = False\n",
    "\n",
    "    for i in range(14):\n",
    "        day = fireDate - timedelta(days=i)\n",
    "        dayWeather = dfWeatherDaily.loc[(dfWeatherDaily['Year'] == day.year) & (dfWeatherDaily['Month'] == day.month) & (dfWeatherDaily['Day'] == day.day)]\n",
    "        if dayWeather.empty:\n",
    "            maxTemps.append(0)\n",
    "            humidities.append(0)\n",
    "            windSpeeds.append(0)\n",
    "        else:\n",
    "            maxTemps.append(dayWeather['MaxTemp'].max())\n",
    "            humidities.append(dayWeather['MeanHumidity'].mean())\n",
    "            windSpeeds.append(dayWeather['MeanWindSpeed'].mean())\n",
    "            if dayWeather['TotalPrecip'].values[0] > 0:\n",
    "                rainBool = True\n",
    "\n",
    "    dfFWEW.at[index, '14daySumMaxTemp'] = sum(maxTemps)\n",
    "    dfFWEW.at[index, '14daySumHumidity'] = sum(humidities)\n",
    "    dfFWEW.at[index, '14daySumWindSpeed'] = sum(windSpeeds)\n",
    "    # true if any day > 0\n",
    "    dfFWEW.at[index, '14dayRain'] = rainBool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfFWEW.count())\n",
    "print(dfFWEW.describe())\n",
    "print(dfFWEW.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "dfFWEW.to_csv('Data/FinalFeatureV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the fires with same utc and average the N day columns\n",
    "dfFWEW = dfFWEW.groupby(['utc', 'YEAR', 'MONTH', 'DAY'], as_index=False).agg({'SIZE_HA':['sum'],\n",
    "                                                     '7daySumMaxTemp':['mean'], '7daySumHumidity':['mean'], '7daySumPrecip':['mean'],\n",
    "                                                     '14daySumMaxTemp':['mean'], '14daySumHumidity':['mean'], '14daySumPrecip':['mean'],\n",
    "                                                     '21daySumMaxTemp':['mean'], '21daySumHumidity':['mean'], '21daySumPrecip':['mean'],\n",
    "                                                     '28daySumMaxTemp':['mean'], '28daySumHumidity':['mean'], '28daySumPrecip':['mean'],\n",
    "                                                     '35daySumMaxTemp':['mean'], '35daySumHumidity':['mean'], '35daySumPrecip':['mean'],\n",
    "                                                     '42daySumMaxTemp':['mean'], '42daySumHumidity':['mean'], '42daySumPrecip':['mean'],\n",
    "                                                     '49daySumMaxTemp':['mean'], '49daySumHumidity':['mean'], '49daySumPrecip':['mean'],\n",
    "                                                     '56daySumMaxTemp':['mean'], '56daySumHumidity':['mean'], '56daySumPrecip':['mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfFWEW.count())\n",
    "print(dfFWEW.describe())\n",
    "print(dfFWEW.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEval = dfFWEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 6 years from 2010-2019 for training\n",
    "dfTrain = dfEval[dfEval['YEAR'].isin([2010, 2011, 2012, 2013, 2014, 2015, 2016])]\n",
    "dfValidate = dfEval[dfEval['YEAR'].isin([2017, 2018])]\n",
    "dfTest = dfEval[dfEval['YEAR'].isin([2019, 2020])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store our random selection, run once\n",
    "randomTrain = \"RandomTrain\"\n",
    "dfTrain.to_sql(randomTrain, db_push_con, if_exists='replace', index=False)\n",
    "\n",
    "randomTest = \"RandomTest\"\n",
    "dfTest.to_sql(randomTest, db_push_con, if_exists='replace', index=False)\n",
    "\n",
    "randomValidate = \"RandomValidate\"\n",
    "dfValidate.to_sql(randomValidate, db_push_con, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainStats = tfdv.generate_statistics_from_dataframe(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.visualize_statistics(trainStats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = tfdv.infer_schema(statistics=trainStats)\n",
    "tfdv.display_schema(schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_train = dfTrain['SIZE_HA'].copy(deep=True)\n",
    "Y_train.fillna(Y_train.mean(), inplace=True)\n",
    "\n",
    "Y_train_discrete = dfTrain['size_ha_bin'].copy(deep=True)\n",
    "Y_train_discrete.fillna(Y_train_discrete.min(), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = dfTrain.drop(columns=['MONTH', 'SIZE_HA', 'OneMonth', 'OneYear', 'TwoMonth', 'TwoYear', 'EntryID', 'size_ha_bin', 'YEAR', 'DAY', 'FIRE_ID', 'FIRENAME', 'ClimateID', 'REP_DATE'])\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_train_one = X_train.drop(columns=['TwoMeanTemp', 'TwoMinTemp', 'TwoMaxTemp', 'TwoMeanDewPoint', 'TwoMinDewPoint', 'TwoMaxDewPoint',\n",
    "                                     'TwoMeanHumidity', 'TwoMinHumidity', 'TwoMaxHumidity', 'TwoMeanPressure', 'TwoMinPressure',\n",
    "                                     'TwoMaxPressure', 'TwoMeanWindSpeed', 'TwoMinWindSpeed', 'TwoMaxWindSpeed', 'TwoMeanWindChill',\n",
    "                                     'TwoMinWindChill', 'TwoMaxWindChill', 'TwoTotalPrecip', 'TwoMeanWindDirection'])\n",
    "X_train_two = X_train.drop(columns=['OneMeanTemp', 'OneMinTemp', 'OneMaxTemp', 'OneMeanDewPoint', 'OneMinDewPoint', 'OneMaxDewPoint',\n",
    "                                     'OneMeanHumidity', 'OneMinHumidity', 'OneMaxHumidity', 'OneMeanPressure', 'OneMinPressure',\n",
    "                                     'OneMaxPressure', 'OneMeanWindSpeed', 'OneMinWindSpeed', 'OneMaxWindSpeed', 'OneMeanWindChill',\n",
    "                                      'OneMinWindChill', 'OneMaxWindChill', 'OneTotalPrecip', 'OneMeanWindDirection'])\n",
    "\n",
    "X_train_means_one = X_train_one.drop(columns=['OneMinTemp', 'OneMaxTemp', 'OneMinDewPoint', 'OneMaxDewPoint', 'OneMinHumidity', 'OneMaxHumidity',\n",
    "                                              'OneMinPressure', 'OneMaxPressure', 'OneMinWindSpeed', 'OneMaxWindSpeed', 'OneMinWindChill',\n",
    "                                              'OneMaxWindChill'])\n",
    "\n",
    "X_train_means_two = X_train_two.drop(columns=['TwoMinTemp', 'TwoMaxTemp', 'TwoMinDewPoint', 'TwoMaxDewPoint', 'TwoMinHumidity', 'TwoMaxHumidity',\n",
    "                                                'TwoMinPressure', 'TwoMaxPressure', 'TwoMinWindSpeed', 'TwoMaxWindSpeed', 'TwoMinWindChill',\n",
    "                                                'TwoMaxWindChill'])\n",
    "\n",
    "dfTrainScaled = dfTrain.copy(deep=True)\n",
    "dfTrainScaled.fillna(dfTrainScaled.mean(), inplace=True)\n",
    "dfTrainScaled = dfTrainScaled.drop(columns=['MONTH', 'OneMonth', 'OneYear', 'TwoMonth', 'TwoYear', 'EntryID', 'size_ha_bin', 'YEAR', 'DAY', 'FIRE_ID', 'FIRENAME', 'ClimateID', 'REP_DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularize y using log scale\n",
    "Y_train = np.log(Y_train)\n",
    "# regularize y values using z score\n",
    "Y_train = (Y_train - Y_train.mean()) / Y_train.std()\n",
    "# set max value to 3 zscore\n",
    "Y_train[Y_train > 3] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainScaled = dfTrain.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainScaled['SIZE_HA'] = np.log(dfTrainScaled['SIZE_HA'])\n",
    "# regularize y values using z score\n",
    "dfTrainScaled = (dfTrainScaled - dfTrainScaled.mean()) / dfTrainScaled.std()\n",
    "# set max value to 3 zscore\n",
    "dfTrainScaled[dfTrainScaled > 3] = 3\n",
    "# set min value to -3 zscore\n",
    "dfTrainScaled[dfTrainScaled < -3] = -3\n",
    "\n",
    "# shift the wole train set to be positive\n",
    "dfTrainScaled = dfTrainScaled + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainStats2 = tfdv.generate_statistics_from_dataframe(dfTrainScaled)\n",
    "tfdv.visualize_statistics(trainStats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one week data\n",
    "weekData = pd.DataFrame()\n",
    "train_dataset = dfTrainScaled.copy(deep=True)\n",
    "\n",
    "# create a dataframe with the 7 day data\n",
    "weekData['7daySumMaxTemp'] = train_dataset['7daySumMaxTemp']\n",
    "weekData['7daySumHumidity'] = train_dataset['7daySumHumidity']\n",
    "weekData['7daySumPrecip'] = train_dataset['7daySumPrecip']\n",
    "weekData['SIZE_HA'] = train_dataset['SIZE_HA']\n",
    "\n",
    "\n",
    "pairplotOne = sns.pairplot(weekData, kind=\"reg\", diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one month data\n",
    "monthData = pd.DataFrame()\n",
    "train_dataset = dfTrainScaled.copy(deep=True)\n",
    "\n",
    "# create a dataframe with the 28 day data\n",
    "monthData['28daySumMaxTemp'] = train_dataset['28daySumMaxTemp']\n",
    "monthData['28daySumHumidity'] = train_dataset['28daySumHumidity']\n",
    "monthData['28daySumPrecip'] = train_dataset['28daySumPrecip']\n",
    "monthData['SIZE_HA'] = train_dataset['SIZE_HA']\n",
    "\n",
    "pairplotTwo = sns.pairplot(monthData, kind=\"reg\", diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two month data\n",
    "twoMonthData = pd.DataFrame()\n",
    "train_dataset = dfTrainScaled.copy(deep=True)\n",
    "\n",
    "# create a dataframe with the 56 day data\n",
    "twoMonthData['56daySumMaxTemp'] = train_dataset['56daySumMaxTemp']\n",
    "twoMonthData['56daySumHumidity'] = train_dataset['56daySumHumidity']\n",
    "twoMonthData['56daySumPrecip'] = train_dataset['56daySumPrecip']\n",
    "twoMonthData['SIZE_HA'] = train_dataset['SIZE_HA']\n",
    "\n",
    "pairplotThree = sns.pairplot(twoMonthData, kind=\"reg\", diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTrainScaled['SIZE_HA'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTemp = pd.DataFrame()\n",
    "dfTemp['SIZE_HA'] = dfTrainScaled['SIZE_HA'].copy(deep=True)\n",
    "# categorize size_ha into 4 classes by quantile\n",
    "dfTrainScaled['SIZE_BIN'] = pd.qcut(dfTemp['SIZE_HA'], 4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(dfTrainScaled.drop(columns=['SIZE_HA']), dfTrainScaled['SIZE_BIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(dfTrainScaled.count())\n",
    "print(dfTrainScaled.isna().sum().sum())\n",
    "print(dfTrainScaled.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0.9  # SVM regularization parameter\n",
    "models = (\n",
    "    svm.SVC(kernel=\"linear\", C=C, decision_function_shape='ovo'),\n",
    "    svm.LinearSVC(C=C, max_iter=10000),\n",
    "    svm.SVC(kernel=\"rbf\", gamma=0.7, C=C, decision_function_shape='ovo'),\n",
    "    svm.SVC(kernel=\"poly\", degree=3, gamma=\"auto\", C=C, decision_function_shape='ovo'),\n",
    ")\n",
    "dfTemp = pd.DataFrame()\n",
    "dfTemp['28daySumMaxTemp'] = dfTrainScaled['28daySumMaxTemp'].copy(deep=True)\n",
    "dfTemp['28daySumHumidity'] = dfTrainScaled['28daySumHumidity'].copy(deep=True)\n",
    "models = (clf.fit(dfTemp, dfTrainScaled['SIZE_BIN']) for clf in models)\n",
    "\n",
    "# title for the plots\n",
    "titles = (\n",
    "    \"SVC with linear kernel\",\n",
    "    \"LinearSVC (linear kernel)\",\n",
    "    \"SVC with RBF kernel\",\n",
    "    \"SVC with polynomial (degree 3) kernel\",\n",
    ")\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2, figsize=(19.20, 10.80))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "X0, X1 = dfTemp['28daySumMaxTemp'], dfTemp['28daySumHumidity']\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        dfTemp,\n",
    "        response_method=\"predict\",\n",
    "        cmap=plt.cm.coolwarm,\n",
    "        alpha=0.8,\n",
    "        ax=ax,\n",
    "        xlabel=['28daySumMaxTemp', '28daySumHumidity'],\n",
    "        ylabel=\"SIZE_BIN\",\n",
    "    )\n",
    "    ax.scatter(X0, X1, c=dfTrainScaled['SIZE_BIN'], cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3014ezH3C7jT"
   },
   "source": [
    "## Define functions that build and train a model\n",
    "\n",
    "The following code defines two functions:\n",
    "\n",
    "  * `build_model(my_learning_rate)`, which builds a randomly-initialized model.\n",
    "  * `train_model(model, feature, label, epochs)`, which trains the model from the examples (feature and label) you pass. \n",
    "\n",
    "Since you don't need to understand model building code right now, we've hidden this code cell.  You may optionally double-click the following headline to see the code that builds and trains a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "pedD5GhlDC-y"
   },
   "outputs": [],
   "source": [
    "#@title Define the functions that build and train a model\n",
    "def build_model(my_learning_rate):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Describe the topography of the model.\n",
    "  # The topography of a simple linear regression model\n",
    "  # is a single node in a single layer.\n",
    "  model.add(tf.keras.layers.Dense(units=1, \n",
    "                                  input_shape=(1,)))\n",
    "\n",
    "  # Compile the model topography into code that TensorFlow can efficiently\n",
    "  # execute. Configure training to minimize the model's mean squared error. \n",
    "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  return model        \n",
    "\n",
    "\n",
    "def train_model(model, df, feature, label, epochs, batch_size):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  # Feed the model the feature and the label.\n",
    "  # The model will train for the specified number of epochs. \n",
    "  history = model.fit(x=df[feature],\n",
    "                      y=df[label],\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs)\n",
    "\n",
    "  # Gather the trained model's weight and bias.\n",
    "  trained_weight = model.get_weights()[0]\n",
    "  trained_bias = model.get_weights()[1]\n",
    "\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "  \n",
    "  # Isolate the error for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  # To track the progression of training, we're going to take a snapshot\n",
    "  # of the model's root mean squared error at each epoch. \n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "  return trained_weight, trained_bias, epochs, rmse\n",
    "\n",
    "print(\"Defined the build_model and train_model functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak_TMAzGOIFq"
   },
   "source": [
    "## Define plotting functions\n",
    "\n",
    "The following [matplotlib](https://developers.google.com/machine-learning/glossary/#matplotlib) functions create the following plots:\n",
    "\n",
    "*  a scatter plot of the feature vs. the label, and a line showing the output of the trained model\n",
    "*  a loss curve\n",
    "\n",
    "You may optionally double-click the headline to see the matplotlib code, but note that writing matplotlib code is not an important part of learning ML programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "QF0BFRXTOeR3"
   },
   "outputs": [],
   "source": [
    "#@title Define the plotting functions\n",
    "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
    "  \"\"\"Plot the trained model against 200 random training examples.\"\"\"\n",
    "\n",
    "  # Label the axes.\n",
    "  plt.xlabel(feature)\n",
    "  plt.ylabel(label)\n",
    "\n",
    "  # Create a scatter plot from 200 random points of the dataset.\n",
    "  random_examples = dfTrainScaled.sample(n=200)\n",
    "  plt.scatter(random_examples[feature], random_examples[label])\n",
    "\n",
    "  # Create a red line representing the model. The red line starts\n",
    "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
    "  x0 = 0\n",
    "  y0 = trained_bias\n",
    "  x1 = 6\n",
    "  y1 = trained_bias + (trained_weight * x1)\n",
    "  plt.plot([x0, x1], [y0, y1], c='r')\n",
    "\n",
    "  # Render the scatter plot and the red line.\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_the_loss_curve(epochs, rmse):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "  plt.plot(epochs, rmse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([rmse.min()*0.97, rmse.max()])\n",
    "  plt.show()  \n",
    "\n",
    "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-IXYVfvM4gD"
   },
   "source": [
    "## Call the model functions\n",
    "\n",
    "An important part of machine learning is determining which [features](https://developers.google.com/machine-learning/glossary/#feature) correlate with the [label](https://developers.google.com/machine-learning/glossary/#label). For example, real-life home-value prediction models typically rely on hundreds of features and synthetic features. However, this model relies on only one feature. For now, you'll arbitrarily use `total_rooms` as that feature. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "nj3v5EKQFY8s"
   },
   "outputs": [],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.01\n",
    "epochs = 30\n",
    "batch_size = 5\n",
    "\n",
    "# Specify the feature and the label.\n",
    "my_feature = \"OneMeanHumidity\"  # the total number of rooms on a specific city block.\n",
    "my_label=\"SIZE_HA\" # the median value of a house on a specific city block.\n",
    "#my_label=\"size_ha_bin\"\n",
    "# That is, you're going to create a model that predicts house value based \n",
    "# solely on total_rooms.  \n",
    "\n",
    "# Discard any pre-existing version of the model.\n",
    "my_model = None\n",
    "\n",
    "# Invoke the functions.\n",
    "my_model = build_model(learning_rate)\n",
    "weight, bias, epochs, rmse = train_model(my_model, dfTrainScaled, \n",
    "                                         my_feature, my_label,\n",
    "                                         epochs, batch_size)\n",
    "\n",
    "print(\"\\nThe learned weight for your model is %.4f\" % weight)\n",
    "print(\"The learned bias for your model is %.4f\\n\" % bias )\n",
    "\n",
    "plot_the_model(weight, bias, my_feature, my_label)\n",
    "plot_the_loss_curve(epochs, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xNqWWos_zyk"
   },
   "source": [
    "## Use the model to make predictions\n",
    "\n",
    "You can use the trained model to make predictions. In practice, [you should make predictions on examples that are not used in training](https://developers.google.com/machine-learning/crash-course/training-and-test-sets/splitting-data). However, for this exercise, you'll just work with a subset of the same training dataset. A later Colab exercise will explore ways to make predictions on examples not used in training.\n",
    "\n",
    "First, run the following code to define the house prediction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nH63BmncAcab"
   },
   "outputs": [],
   "source": [
    "def predict_house_values(n, feature, label):\n",
    "  \"\"\"Predict house values based on a feature.\"\"\"\n",
    "\n",
    "  batch = dfTrainScaled[feature][200:200 + n]\n",
    "  predicted_values = my_model.predict_on_batch(x=batch)\n",
    "\n",
    "  print(\"feature   label          predicted\")\n",
    "  print(\"  value   value          value\")\n",
    "  print(\"          in thousand$   in thousand$\")\n",
    "  print(\"--------------------------------------\")\n",
    "  for i in range(n):\n",
    "    print (\"%5.0f %6.0f %15.0f\" % (dfTrain[feature][400+i], dfTrain[label][400+i], predicted_values[i][0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_0DGBt0Kz_N"
   },
   "outputs": [],
   "source": [
    "predict_house_values(10, my_feature, my_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:42:03) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef7e3ad1fe0a4a5293cd6ca311ffca45c667fb34d948e973384e8d54f12a93f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
